<?xml version="1.0" encoding="UTF-8"?>

<rss version="2.0"
  xmlns:content="http://purl.org/rss/1.0/modules/content/"
  xmlns:dc="http://purl.org/dc/elements/1.1/"
  xmlns:media="http://search.yahoo.com/mrss/"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:georss="http://www.georss.org/georss">

  <channel>
    <title>
      <![CDATA[  Finn Hambly  ]]>
    </title>
    <link> https://finnhambly.com </link>
    <description>
      <![CDATA[  Finn&#39;s personal blog  ]]>
    </description>
    <atom:link
      href="https://finnhambly.com/feed.xml"
      rel="self"
      type="application/rss+xml" />


<item>
  <title>
    <![CDATA[  What if we&#39;re already digital?  ]]>
  </title>
  <link> https://finnhambly.com/blog/alreadydigital/index.html </link>
  <guid> https://finnhambly.com/blog/alreadydigital/index.html </guid>
  <description>
    <![CDATA[  If you think we live in a pivotal time, maybe you should update your metaphysical beliefs.  ]]>
  </description>  
  
  <content:encoded>
    <![CDATA[  
<h1 id="what_if_were_already_digital">What if we&#39;re already digital?</h1>
<p><em>TL;DR: P&#40;simulation|important&#41; &gt; P&#40;simulation|¬important&#41;</em></p>
<p><em>If we are living in a particularly important century, the probability that we&#39;re in a simulation increases.</em></p>
<p><em>Disclaimer: This post is kind of weird. Sorry.</em></p>
<div class="franklin-toc"><ol><li>Is this century important?</li><li>P&#40;simulation&#41;<ol><li>The simulation hypothesis</li></ol></li><li>Why would we be simulated? P&#40;important | simulation&#41;?<ol><li>Anthropic reasoning all the way up</li></ol></li><li>Filling out the formula for P&#40;simulation | important&#41;</li><li>Ramifications</li></ol></div>
<h2 id="is_this_century_important">Is this century important?</h2>
<p>This month, Effective Ideas are offering mini prizes for blogs that discuss Holden Karnofsky&#39;s series on <a href="https://www.cold-takes.com/most-important-century/">The Most Important Century</a> — a set of blogposts that make a sober, clear-headed case that we live in an extraordinary era that will define the trajectory of human civilisation more than any other. Outlandish claims that have significant implications, such as those that Karnfosky discusses, are often dismissed simply because they are esoteric — but some ought to be taken seriously.</p>
<p>If it&#39;s true, it does seem to be quite a coincidence that we happen to be alive in the most important century&#33; I wanted to discuss the implications of observing something quite so coincidental, but I realised that there are nuances to my views on what qualifies as &#39;important&#39;. To try and clarify my thoughts here, I wrote my version of the &#39;most important century&#39; thesis in <a href="https://finnhambly.com/blog/attractorstates">my last blogpost</a>, explaining why our choices might alter humanity&#39;s future trajectory in a way that no previous &#40;or future&#41; century could.</p>
<p>One of the most significant factors that makes this century seem so uniquely important is the possibility of digital minds. If you need convincing on the feasibility of this or want to know why their creation would be so consequential, the best resource is Karnofsky&#39;s post <a href="https://www.cold-takes.com/how-digital-people-could-change-the-world/">Digital People Would Be An Even Bigger Deal</a>. The importance of this century doesn&#39;t just rest on digital people being created, but observing even the <em>possibility</em> of conscious digital people is notable. If it&#39;s possible to simulate conscious beings, then <em>we</em> could be simulated.</p>
<div class="marginnote">While we may create digital people, the simulation we&#39;re in wouldn&#39;t necessarily be <em>digital</em> — our existence may depend on &#39;reals&#39;, qubits, or something unfathomable to us, rather than bits.</div>
<h2 id="psimulation">P&#40;simulation&#41;</h2>
<div class="img-med"><img src="https://finnhambly.com/assets/digitalwoods.png" alt="" /></div>
<div class="caption">“Maybe you think the glorious forest around you proves that your world isn’t a simulation. But in principle, the forest could be simulated down to every last detail, and every last bit of light that reaches your eyes from the forest could be simulated, too. Your brain will react exactly as it would in the nonsimulated, ordinary world, so a simulated forest will look exactly like an ordinary one. Can you really prove that you aren’t seeing a simulated forest?&quot; <br/> &#40;<em>Reality&#43;</em> by David Chalmers&#41;</div>
<p>I recently read David Chalmers&#39; book <a href="http://consc.net/reality/"><em>Reality&#43;</em></a>, which is a piece of &#39;technophilosophy&#39; that does a pit-stop tour of the big questions in philosophy with thought experiments based around modern technology:</p>
<div class="img-med"><img src="https://finnhambly.com/assets/modernplatocave.png" alt="" /></div>
<p>Its central argument is that virtual reality is genuine reality but also, along the way, makes you realise that the simulation hypothesis has quite significant implications. Most people react to the simulation hypothesis with indifference — &quot;so what if we&#39;re in a simulation?&quot; — but if you care about the value of the long-run future, it could matter a great deal.</p>
<h3 id="the_simulation_hypothesis">The simulation hypothesis</h3>
<p>The simulation hypothesis is simply the hypothesis that we are living in a simulation, and proponents of it tend to think it is probably true because of arguments like the following &#40;given by Chalmers&#41;:</p>
<p>&#40;sim &#61; someone who is in a simulation&#41;</p>
<blockquote>
<ul>
<li><p>At least one in ten nonsim populations will each create a thousand sim populations.<br/></p>
</li>
<li><p>If at least one in ten nonsim populations will each create a thousand sim populations, then at least 99 percent of intelligent beings are sims.<br/></p>
</li>
<li><p>If at least 99 percent of intelligent beings are sims, we are probably sims.<br/></p>
</li>
</ul>
<hr />
<ul>
<li><p>So: We are probably sims.</p>
</li>
</ul>
</blockquote>
<p>It&#39;s reasonable to suppose that there would be things that stop nonsim populations from creating sims. For instance, they might choose to not create sims that are conscious, perhaps out of moral concerns. We might want to reduce the probability of being simulated due to that, but it seems unlikely that <em>all</em> capable nonsims would avoid spinning up consciousnesses.</p>
<p>Objections like these might prevent the existence of simulated people, but Chalmers packages this up neatly into the following conclusion:</p>
<blockquote>
<p>we should be highly confident that either &#40;1&#41; we are sims, or &#40;2&#41; humanlike sims are impossible, or &#40;3&#41; humanlike sims are possible but few humanlike nonsims will create them.</p>
</blockquote>
<div class="marginnote">If human-like sims are impossible &#40;scenario 2&#41; 50&#37; of the time, that leaves a 50&#37; chance that they are possible. In these remaining situations, if there&#39;s 50&#37; chance that nonsims avoid creating sims, there&#39;s a 25&#37; chance that ~all conscious beings are sims.</div>
<p>Chalmers thinks &#40;as do I&#41; that &#40;2&#41; and &#40;3&#41; are unlikely; there&#39;s no obvious reason why human-like sims aren&#39;t possible, and the incentives to create them are <a href="https://www.cold-takes.com/the-duplicator/">so strong</a>. So what&#39;s the probability that we&#39;re in a simulation? I don&#39;t know, but if we&#39;re generous to the sceptics and say that &#40;2&#41; and &#40;3&#41; each have a 50&#37; chance of being true, P&#40;simulation&#41; &#61; 25&#37;.</p>
<h2 id="why_would_we_be_simulated_pimportant_simulation">Why would we be simulated? P&#40;important | simulation&#41;?</h2>
<p>Some more from Chalmers:</p>
<blockquote>
<p>Theology is &#40;roughly&#41; the study of the nature of God from the point of view of God’s subjects. Simulation theology is the study of the nature of the simulator-as-God from the point of view of those within the simulation. We, too, can engage in simulation theology. Under the assumption that we’re living in a simulation, we can speculate about the nature of our simulator. Is the simulator probably humanlike, or some sort of artificial intelligence? Is the simulator running the simulation for entertainment? For science? For decision-making? For historical analysis?</p>
</blockquote>
<p><img src="https://finnhambly.com/assets/simsigns.png" alt="" /></p>
<p>Why would our simulators be simulating us? My guess is that any simulator is likely to simulate a population fairly similar to their own. From our own observations, we can see that humans — like our hypothetical simulator — find value in running simulations. Additionally, whether it&#39;s for scientific purposes or a video game, our simulations are designed to be similar to our universe in some way. The less a hypothetical simulation has in common with its simulator&#39;s universe, the less likely it will be.</p>
<p>&#40;Some aspects of the simulation may be different to the world above by necessity. For instance, we may have had our simulation capabilities restricted or delayed, in order to conserve our simulator&#39;s computational resources.&#41;</p>
<p>So why would anyone expend their resources to simulate a universe like ours? Maybe it&#39;ll be for some relatively trivial matter, like finding out the universal, long-run effects of a new kind of detergent. However, it&#39;s reasonable to expect the quantity of computational resources &#40;and hence number of simulations&#41; to scale with the importance of the subject.</p>
<p>Because of that, the fact that this period of time looks particularly important, due to the highly consequential decisions we&#39;ll be making, is a pretty strong sim sign.</p>
<h3 id="anthropic_reasoning_all_the_way_up">Anthropic reasoning all the way up</h3>
<p>If simulations successfully help you protect yourself, you could go even further and claim that simulations of <em>exactly this type of scenario</em> are going to be generated in abundance. If the simulations are recursive &#40;i.e. there are simulations within the simulations&#41;, the most common decisions about what to simulate are going to be made by sims that manage to survive. So the sim civilisations with self-preserving tendencies are going to account for a much larger share of sims.</p>
<p>On first inspection, the claim that we live in the most important century seems immediately dubious to many. Statistically, it seems implausible. And we might be biased in our assessment: we may want it to be true, even if it&#39;s just for our own egos. If our century is important, then <em>we</em> can be important too.</p>
<p>What&#39;s even more dubious is claiming not only &#40;1&#41; that we live in the most important century, but &#40;2&#41; that this century is why our universe exists in the first place&#33; It&#39;s a whole new level of narcissism. To help you assess whether this is just motivated reasoning, I&#39;ll give you some numbers.</p>
<h2 id="filling_out_the_formula_for_psimulation_important">Filling out the formula for P&#40;simulation | important&#41;</h2>
<p>The probability that universes will want to simulate important things seems like it&#39;ll be high, but perhaps they&#39;ll mainly simulate things for entertainment or worthless market research. </p>
<p>To craft a prior for the ratio of &#39;important&#39; simulations to &#39;not important&#39; simulations, let&#39;s look at how compute usage is currently distributed. In 2015, <a href="https://aiimpacts.org/global-computing-capacity/">global computing capacity</a> was probably between \(2 \times 10^{20}\) and \(1.5 \times 10^{21}\) FLOP/s. Responsible for a portion of that computing capacity was <a href="https://www.top500.org/lists/top500/2015/06/">the TOP500</a> supercomputers — which tend to be used for pretty important things — and their total performance came to \(3.61 \times 10^{18}\) FLOP/s, or 0.24–1.8&#37; of the world&#39;s computational power. So, for simplicity, let&#39;s say these supercomputers did the only &#39;important&#39; computing in 2015, and assume civilisations that run simulations split their resources similarly. That gives us 1&#37; as a low-ball guess for the percentage of simulations deserving the label &#39;important&#39;:</p>
<div class="nonumber">\[ P(important|sim) = 0.01 \]</div>
<p>And, as calculated earlier, we can claim there is something like a 25&#37; chance that we are living in a simulation: <div class="nonumber">\[ P(sim) = 0.25 \]</div></p>
<p>Getting a prior probability for living during an important time is pretty tricky to work out. Using <a href="https://www.cold-takes.com/forecasting-transformative-ai-whats-the-burden-of-proof/">Holden Karnofsky&#39;s priors</a>, the chance we landed in the <em>most</em> important century is around 1 in 100,000 to 1 in 1,000. How about other centuries that were important, even if they weren&#39;t number one? </p>
<p>They didn&#39;t all last for a century — and forgive me for not accounting for population changes or important centuries in the future — but there are 13 technological revolutions on <a href="https://en.wikipedia.org/wiki/Technological_revolution#List_of_intellectual,_philosophical_and_technological_revolutions_&#40;sectoral_or_universal&#41;">this list</a> so I&#39;m going to use that to say there have been 13 &#39;important&#39; centuries. &#40;My reasoning for what counts as &#39;important&#39; was discussed in my <a href="https://finnhambly.com/blog/attractorstates.md">last post</a>.&#41; With all that, I&#39;ll say 13 in every 10,000 centuries counts as important &#40;by my lights&#41;.</p>
<p><div class="nonumber">\[ P(important) = P(important|sim)·P(sim) + P(important|¬sim)·P(¬sim) \]</div> <div class="nonumber">\[ P(important) = 0.01 · 0.25 + \frac{13}{10,000}·0.75 = 0.003475\]</div></p>
<p>So, given that this century seems to be important, how much should I update my probability that we&#39;re in a simulation?</p>
<p><div class="nonumber">\[ P(sim | important) = \frac{P(important|sim)•P(sim)}{P(important)}\]</div> <div class="nonumber">\[ P(sim | important) = \frac{0.01•0.25}{0.003475}\]</div> <div class="nonumber">\[ P(sim | important) ≈ 0.7 \]</div></p>
<p>So — if we are indeed in a uniquely important time — I should update my beliefs of being in a simulation from 25&#37; to 70&#37;&#33; At a minimum&#33;</p>
<div class="img-med"><img src="https://finnhambly.com/assets/simulationart.png" alt="" /></div>
<div class="caption">I&#39;m inclined to name this one the &#39;it-from-bit hypothesis&#39;.</div>
<p><em>Note: this result is very sensitive to the ratio of P&#40;important|sim&#41; to P&#40;important|¬sim&#41;, but the factor of 7 implied with these numbers seems like a pretty lowball guess to me, and higher numbers only increase the chances that an important century is simulated.</em></p>
<h2 id="ramifications">Ramifications</h2>
<p>In a bullet point in <a href="https://www.cold-takes.com/all-possible-views-about-humanitys-future-are-wild/">All Possible Views About Humanity&#39;s Future Are Wild</a>, Karnofsky mentions the simulation hypothesis as a reason to be sceptical about humanity ever spreading throughout the galaxy. However, I don&#39;t think being in a simulation necessarily implies we should take his <a href="https://www.cold-takes.com/call-to-vigilance/">call to vigilance</a> less seriously.</p>
<p>Granted, our simulators might terminate us as soon as we navigate through this time of perils. But even then, while our future might be smaller, the universe&#40;s&#41; above us would be even more vast than our own. If we survive these challenges in a way that sets humanity up for a wonderful, valuable future, our approach may be adopted by those observing us. May our best values propagate upwards&#33;</p>
<script src="https://utteranc.es/client.js"
    repo="finnhambly/finnhambly.github.io"
    issue-term="pathname"
    theme="github-light"
    crossorigin="anonymous"
    async>
</script> ]]>
  </content:encoded>
    
  <pubDate>Mon, 01 Aug 2022 00:00:00 +0000</pubDate>  
  
  
  <atom:author>
    <atom:name>Finn Hambly</atom:name>
  </atom:author>
        
</item>

<item>
  <title>
    <![CDATA[  A minefield of attractor states  ]]>
  </title>
  <link> https://finnhambly.com/blog/attractorstates/index.html </link>
  <guid> https://finnhambly.com/blog/attractorstates/index.html </guid>
  <description>
    <![CDATA[  This century is important because we can knowingly improve the long-run future.  ]]>
  </description>  
  
  <content:encoded>
    <![CDATA[  
<h1 id="a_minefield_of_attractor_states">A minefield of attractor states</h1>
<div class="franklin-toc"><ol><li>What makes a particular era important?<ol><li>Importance ≈ expected impact - the counterfactual</li></ol></li><li>Choices during technological transitions don&#39;t usually have persistent effects<ol><li>Why it looks different this time: a minefield of attractor states<ol><li>Extinction scenarios</li><li>Non-extinction scenarios</li></ol></li></ol></li><li>Getting the transition right</li></ol></div>
<p>In this post, I articulate my version of Holden Karnofsky&#39;s thesis that we could be living in <a href="https://www.cold-takes.com/most-important-century/">the most important century</a>, with an emphasis on why this century&#39;s level of influence is distinct. If you&#39;ve not read the series, and find the claims in this post to be absurd, then I highly recommend checking out &#40;at least&#41; the <a href="https://www.cold-takes.com/most-important-century/">summary</a> and the post <a href="https://www.cold-takes.com/all-possible-views-about-humanitys-future-are-wild/">All Possible Views About Humanity&#39;s Future Are Wild</a>.</p>
<p>My argument is &#40;roughly&#41;:</p>
<ul>
<li><p>humanity falling into an &#39;attractor state&#39; is very significant,</p>
</li>
<li><p>the more influence we have over that possibility, the more important this era is, and</p>
</li>
<li><p>this seems to be the case, moreso than ever.</p>
</li>
</ul>
<h2 id="what_makes_a_particular_era_important">What makes a particular era important?</h2>
<p>In the series, Karnofksy discusses technologies that are on our horizon, how they will transform humanity, and how unreasonable it is that almost nobody seems to care. Living through a technological revolution is not, however, unprecedented. Wikipedia has a <a href="https://en.wikipedia.org/wiki/Technological_revolution#List_of_intellectual,_philosophical_and_technological_revolutions_&#40;sectoral_or_universal&#41;">nice list of intellectual, philosophical, and technological revolutions</a> which includes the Upper Neolithic Revolution, the First Industrial Revolution, and this figure demonstrating how technological progress means we can shoot our butter and eat it too:</p>
<div class="img-small"><img src="https://finnhambly.com/assets/ppfrontier.png" alt="" /></div>
<div class="caption">Expanding the <a href="https://en.wikipedia.org/wiki/Production–possibility_frontier">production-possibility frontier</a> for only the essentials.</div>
<p>Designating a single era as the most decisive is tricky, of course, but focusing on revolutions makes sense. Discontinuous changes like technological innovations &#40;a <a href="https://en.wikipedia.org/wiki/Zero_to_One">0 &rarr; 1</a> change&#41; seem more impressive and significant than the subsequent propagation and advancement of those technologies &#40;1 &rarr; n changes&#41;. For example, the creation of useful steam engines &#40;0 &rarr; 1&#41; seems more notable than the subsequent improvements and scaling of our power generation &#40;1 &rarr; n&#41;, despite the latter accounting for significantly more economic activity and impacted lives.</p><iframe src="https://ourworldindata.org/grapher/global-energy-substitution?country=~OWID_WRL" loading="lazy" style="width: 100%; height: 600px; border: 0px none;"></iframe><p>This is easily justified since the value accrued from 1 to n can just be attributed to those who went from 0 to 1 in the first place. But that logic leads you to the trivial conclusion that no era is particularly important, as it fully depends on the shifts that came before it &#40;from human evolution, to the emergence of life, to the birth of the universe&#41;. Everything we do is &#40;1&#41; defined by the past and &#40;2&#41; defines the future; this is quite normal.</p>
<h3 id="importance_expected_impact_-_the_counterfactual">Importance ≈ expected impact - the counterfactual</h3>
<p>But I don&#39;t think 0 &rarr; 1 events are impressive just because they are the start of something big. They&#39;re impressive because the value of their counterfactuals — the circumstances in which the event didn&#39;t take place — would have been <em>predictably different</em>. While many unprecedented events seem inevitable in retrospect, their timing and expected impact are not predetermined. </p>
<p>For example, the smallpox vaccine was created in 1798, but the virus remained widespread for the next century-and-a-half, with 50 million cases occurring each year in the early 1950s. In 1958, <a href="https://80000hours.org/2012/02/in-praise-of-viktor-zhdanov/">Viktor Zhdanov</a> initiated a campaign to eradicate smallpox; he convinced the World Health Assembly to undertake this challenge when no disease had ever been eradicated before.  A few years before this, <a href="https://www.worksinprogress.co/the-story-of-viktor-zhdanov/">the Assembly had rejected a similar proposal</a> because it was &#40;understandably&#41; deemed too unrealistic. But thanks to Zhdanov&#39;s determination, the Assembly took on the challenge.</p>
<div class="marginnote">Seriously, take 3 minutes to read <a href="https://forum.effectivealtruism.org/posts/jk7A3NMdbxp65kcJJ/500-million-but-not-a-single-one-more">500 Million, But Not A Single One More</a>.</div>
<p>By 1979 the programme had succeeded. The virus that killed 500 million people <a href="https://forum.effectivealtruism.org/posts/jk7A3NMdbxp65kcJJ/500-million-but-not-a-single-one-more">was gone</a>. </p>
<p>How long would it have been before someone had both the expertise and the initiative to successfully set a campaign like that in motion? And with <a href="https://ourworldindata.org/smallpox#how-many-died-of-smallpox">300 million dying in the 20<sup>th</sup> century alone</a>, all delays are devastatingly tragic. </p>
<p>In contrast, if the <a href="https://en.wikipedia.org/wiki/Last_universal_common_ancestor">organisms at the start</a> of our evolutionary lineage had never formed, life &#40;in all likelihood&#41; would have evolved from some other H\(_2\)-dependent autotrophs &#40;or whatever&#41; within the next billion years, since the conditions for such an event to occur were set up. Slight deviations in the origins of life change everything, but not in any predictable way. There&#39;s little <em>ex ante</em> reason why any one starting point would be better or worse than another. Of course, <em>ex post</em>, I&#39;m glad things went how they did &#40;otherwise we wouldn&#39;t be here&#41;, but the value of future evolved species cannot be straightforwardly inferred from the composition of the chemical soups that microorganisms self-assembled in.</p>
<p>This is related to <a href="https://80000hours.org/podcast/episodes/hilary-greaves-global-priorities-institute/">cluelessness</a>; every decision &#40;regardless of its perceived significance&#41; will lead to consequences that will completely alter the future state of the universe. However, in most instances, the <em>expected change</em> in the value of the long-run future is distributed symmetrically around zero, for whichever decision you take. </p>
<p>With this thinking, the emergence of technological maturity doesn&#39;t <em>necessarily</em> make the preceding decisions important, since the most significant counterfactuals may have been ruled out a long time ago. So, if we live at the <a href="https://forum.effectivealtruism.org/topics/hinge-of-history">hinge of history</a>, it doesn&#39;t make this time the most important by default. Maybe our only task is to open the door. </p>
<p>Are the actions we take over the next century plagued by moral cluelessness? Or, like eradicating smallpox, can we make choices that are clearly, massively good for the world?</p>
<h2 id="choices_during_technological_transitions_dont_usually_have_persistent_effects">Choices during technological transitions don&#39;t usually have persistent effects</h2>
<p>Holden Karnofsky &#40;reasonably&#41; believes the next technological transition will change everything. If the future involves transitioning to digital life, he claims that <a href="https://www.cold-takes.com/how-digital-people-could-change-the-world/">the nature of our transition will have a lasting influence</a>:</p>
<blockquote>
<p>acceptably good initial conditions &#40;protecting basic human rights for digital people, at a minimum&#41;, plus a lot of patience and accumulation of wisdom and self-awareness we don&#39;t have today &#40;perhaps facilitated by better social science&#41;, could lead to a large, stable, much better world. It should be possible to eliminate disease, material poverty and non-consensual violence, and create a society much better than today&#39;s.</p>
</blockquote>
<p>You could imagine a &#40;particularly visionary&#41; person saying that about the industrial revolution, but I don&#39;t think the initial conditions mattered that much in the long run. It would have been wrong to claim that actions taken during that period of time would lock our society into a certain set of values. You could argue that the amount of capital and power that a small set of people accumulated put us on a narrow path that we cannot escape from, but I&#39;m not convinced. As Dwarkesh Patel puts it in <a href="https://www.dwarkeshpatel.com/p/the-simmer-scenario">This Can Go On</a>:</p>
<blockquote>
<p>The development of the printing press resulted in wars, revolutions, religions, political movements, and further scientific and technological advances which have completely remade the world. In the simmer scenario &#91;0.2&#37; growth a year for 25,000 years&#93;, a technology as fundamental as that is being developed every 500 years for the remainder of our time in the galaxy. In this scenario, no century ends up having extraordinarily important technological changes in the grand scheme of things.</p>
</blockquote>
<p>But maybe, if the technologies were more transformative and the transition more discontinuous, the users of the first printing presses would have entirely determined humanity&#39;s subsequent trajectory. Karnofsky claims that this may be the case now:</p>
<blockquote>
<p>During the century we’re in right now, we will develop technologies that cause us to transition to a state in which humans as we know them are no longer the main force in world events. This is our last chance to shape how that transition happens.</p>
</blockquote>
<p>In other words, this transition is different because it won&#39;t just induce change, but may eternally restrict humanity&#39;s capacity for it. This is a strong claim but, if the future holds a large number of digital people, it is hard to dispute <a href="https://www.cold-takes.com/how-digital-people-could-change-the-world/">Karnofsky&#39;s reasoning</a>. Just a couple of transformative technologies &#40;artificial intelligence and digital consciousness&#41; could lead to human extinction or a permanent, galaxy-wide, dystopian regime — both examples of &#39;attractor states&#39;. </p>
<h3 id="why_it_looks_different_this_time_a_minefield_of_attractor_states">Why it looks different this time: a minefield of attractor states</h3>
<blockquote>
<p>The human race’s prospects of survival were considerably better when we were defenceless against tigers than they are today, when we have become defenceless against ourselves.</p>
</blockquote>
<div class="attribution">– Arnold Toynby</div>
<p>An attractor state is a condition where, once you enter it, you cannot escape — like a black hole. As Greaves and MacAskill <a href="https://globalprioritiesinstitute.org/hilary-greaves-william-macaskill-the-case-for-strong-longtermism-2/">put it</a>: &quot;The non-existence of humanity is a persistent state par excellence. To state the obvious: the chances of humanity re-evolving, if we go extinct, are minuscule&quot;.</p>
<div class="img-med"><img src="https://finnhambly.com/assets/attractorstate.png" alt="" /></div>
<div class="caption">I prompted <a href="https://www.midjourney.com/">Midjourney</a> with the words &#39;attractor state&#39; and received <a href="https://finnhambly.com/assets/attractorstate.png">some lovely art</a>.</div>
<h4 id="extinction_scenarios">Extinction scenarios</h4>
<p>Take a look at these forecasts on how likely it is that various global catastrophes kill over 95&#37; of the human population &#40;and see <a href="https://www.metaculus.com/notebooks/8736/a-global-catastrophe-this-century/">this notebook</a> for background information&#41;:</p><iframe src="https://www.metaculus.com/questions/embed/2514/?theme=default" width="100%" height="260"></iframe><iframe src="https://www.metaculus.com/questions/embed/2513/?theme=default" width="100%" height="260"></iframe><iframe src="https://www.metaculus.com/questions/embed/9051/?theme=default" width="100%" height="260"></iframe><iframe src="https://www.metaculus.com/questions/embed/7795/?theme=default" width="100%" height="260"></iframe><p>A &#39;catastrophe&#39; in these instances refers to an event that kills 10&#37; of the world&#39;s population. The Metaculus community places a 66&#37; chance of this kind of event taking place this century, with AI &#40;the most severe threat&#41; being involved in ~25&#37; of them.</p>
<p>Being able to wipe ourselves out this easily is an incredibly new phenomenon; the concept of humanity being rendered extinct by their own discoveries became salient last century with the invention and proliferation of nuclear weapons. But, if a nuclear catastrophe kills 10&#37; of the population &#40;which is deemed to be roughly as likely as an AI, biological, or &#39;other&#39; catastrophe doing the same&#41;, the likelihood that it kills 95&#37; of the population is significantly lower:</p><iframe src="https://www.metaculus.com/questions/embed/1585/?theme=default" width="100%" height="260"></iframe><p>All of these probabilities are unacceptably high, and the severity of these risks is much worse than most people account for. This scenario makes our century uniquely dangerous and, since there&#39;s still so much we can do to reduce them, uniquely important.</p>
<h4 id="non-extinction_scenarios">Non-extinction scenarios</h4>
<p>In The Precipice, Toby Ord uses the term &#39;existential catastrophe&#39; to describe humanity &quot;getting locked into a bad set of futures&quot;. Among these bad futures, Ord includes an ‘unrecoverable dystopia’: “a world with civilization intact, but locked into a terrible form, with little or no value”. This would be deemed to be an ‘attractor state’ of significantly lower expected value than alternative possible futures, alongside human extinction.</p>
<p>So if we succeed at avoiding extinction, things could still go horribly wrong. Karnofsky and Ord articulate how and why unrecoverable dystopias may arise, but the number of paths to such an attractor state seems more numerous than you&#39;d initially guess.</p>
<p>For example, to avoid extinction scenarios, humanity may choose to install some stable, global, safety-enhancing regime, as described by Nick Bostrom in <a href="https://nickbostrom.com/papers/vulnerable.pdf">the vulnerable world hypothesis</a>. This flavour of attractor state doesn&#39;t give me much hope, sadly. For something as totalizing and irreversible as locking in a world government, I would want infeasible levels of certainty about how good it will be.</p>
<p>But, within this minefield of attractor states, not all of them must be entered into suddenly.</p>
<p>If humanity spreads across the galaxy — creating civilisations that are disparate and diverse — the chances of our survival in a given millenium may well spring back to ~100&#37;. This, the secured persistence humanity, is its own &#40;more subtle&#41; attractor state.</p>
<h2 id="getting_the_transition_right">Getting the transition right</h2>
<p>To me, it seems like we&#39;re in a position where we can make choices that are genuinely good for the long-run future; reducing the chance of a civilisational catastrophe, at a minimum, seems like an obviously good bet. Beyond that, there are many other attractor states we could increase the chances of — and doing so would be incredibly consequential.</p>
<p>Because of this, I think the 21<sup>st</sup> century will be unmatched in terms of <strong>the variance in the expected impact of our actions</strong> since we can knowingly alter the probability distribution of humanity&#39;s future trajectories within this incredibly large range:</p>
<p><img src="https://finnhambly.com/assets/this-cant-go-on.png" alt="" /></p>
<div class="caption">From <a href="https://www.cold-takes.com/this-cant-go-on">This Can&#39;t Go On</a>.</div>
<p>As we consider how the future should look, we should be wary of most lock-in scenarios. This is obvious when most of the visible attractor states look really bad, but I also think it&#39;s unwise to get locked into any path &#40;even if they look good&#41;. It may well be our last chance to define the future, but let&#39;s be stewards of humanity&#39;s existence rather than legacy builders. I&#39;ll explain my full reasoning for that in a future post but, for now, I want to tell you <a href="https://finnhambly.com/blog/alreadydigital">why this thesis supports the simulation hypothesis</a>, despite how silly that sounds.</p>
<script src="https://utteranc.es/client.js"
    repo="finnhambly/finnhambly.github.io"
    issue-term="pathname"
    theme="github-light"
    crossorigin="anonymous"
    async>
</script> ]]>
  </content:encoded>
    
  <pubDate>Sun, 31 Jul 2022 00:00:00 +0000</pubDate>  
  
  
  <atom:author>
    <atom:name>Finn Hambly</atom:name>
  </atom:author>
        
</item>

<item>
  <title>
    <![CDATA[  Validation as a bottleneck for agency  ]]>
  </title>
  <link> https://finnhambly.com/blog/agency/index.html </link>
  <guid> https://finnhambly.com/blog/agency/index.html </guid>
  <description>
    <![CDATA[  I think our capacity to act is a result of our social environments and, rather than rely on pure self-encouragement, we ought to focus on fostering supportive networks.  ]]>
  </description>  
  
  <content:encoded>
    <![CDATA[  
<h1 id="validation_as_a_bottleneck_for_agency">Validation as a bottleneck for agency </h1>
<div class="franklin-toc"><ol><li>Vibes I get from other blogposts on this topic</li><li>Cultural approaches to increasing individuals’ agency</li><li>Cute stories about supportive social circles</li><li>Managing how we&#39;re affected by our environments</li><li>Some personal reflections</li></ol></div>
<p><em>TL;DR: I think our capacity to act is a result of our social environments and, rather than rely on pure self-encouragement, we ought to focus on fostering supportive networks.</em></p>
<h2 id="vibes_i_get_from_other_blogposts_on_this_topic">Vibes I get from other blogposts on this topic</h2>
<p>Most blog posts I’ve read about being more agentic encourage being very explicitly ambitious, but I often find them sort of… sad? This might be because I’m personally repelled by ‘grind culture’ mindsets, and find proclamations that start with “you should” annoying. </p>
<p>Personally, I think of agency as &quot;having ideas and doing them&quot;, often without registering the fact that you’re trying to “do a thing”. There are a lot of prerequisites to this, and I think a crucial one is being in an environment that gives you energy and confidence, rather than listening to bloggers telling you to grit your teeth and do socially-uncomfortable things.</p>
<blockquote>
<p>Why are you telling me what to do? You don’t know me.</p>
</blockquote>
<div class="attribution">– Me, talking to my computer, after reading too many normative blog posts</div>
<p>I just googled ‘what does it mean to have agency’ and Wikipedia says that it’s the “capacity of individuals to have the power and resources to fulfill their potential”. I quite like that definition, because it’s made me realise that the blogs I’ve read on this topic either:</p>
<ol>
<li><p>tell the reader that they, as an individual, have the power and resources they need &#40;and to act on it for God’s sake&#41;, or</p>
</li>
<li><p>describe cultural forces that alter an individual’s sense of agency.</p>
</li>
</ol>
<p>And this second category is one I like. It’s not just because I enjoy social commentary, but because this commentary can actually make <a href="https://en.wikipedia.org/wiki/Yes,_and...">“Yes, and...” thinking</a> a norm.</p>
<p>This matters because I think an ambitious person&#39;s agency is bounded more by their environment than the strength of their determination. The latter helps, of course, but it seems hard to sustain &#40;even if they are quite brilliant&#41;.</p>
<p>Below, I provide some examples of blogposts that I think nudge readers to be a little more encouraged and encouraging, in an indirect way. If you&#39;re not interested, skip to the next section.</p>
<h2 id="cultural_approaches_to_increasing_individuals_agency">Cultural approaches to increasing individuals’ agency</h2>
<p><strong>Illustrative example 1</strong>: labelling the automatic dismissal of ideas as part of a <a href="https://normielisation.substack.com/p/cheems-mindset">cheems mindset</a> makes it very uncool and, consequently, pushes everyone who reads it to be a bit more receptive to new ideas.</p>
<p><img src="https://finnhambly.com/assets/agency-cheems.png" alt="" /></p>
<div class="caption">To give some visual excitement to this blogpost, I generated this meme with GPT-3.</div>
<p><strong>Representative case number two</strong>: <a href="https://www.lesswrong.com/posts/dhj9dhiwhq3DX6W8z/hero-licensing">Hero Licensing</a> highlights how people can find ambitiousness to be outrageous and require it to be well-justified, even though this is often a waste of time. As well as dunking on the cheems mindset, I think Eliezer Yudkowsky is trying to motivate ‘uncredentialed nobodies’ to ignore the haters and save the world. &#40;If you want to motivate me, tell me how others are wrong for not believing in me, rather than telling me to try harder.&#41; Related: <a href="https://forum.effectivealtruism.org/posts/HX9ZDGwwSxAab46N9/you-don-t-need-to-justify-everything">You Don&#39;t Need To Justify Everything</a></p>
<blockquote>
<p>Well, I don’t think you can save the world, of course&#33;  &#40;laughs&#41;  This isn’t a science fiction book.</p>
</blockquote>
<div class="attribution">— Pat Modesto, an insufferable figment of Eliezer Yudkowsky’s imagination</div>
<p><strong>Specimen #3</strong>: <a href="https://alexdanco.com/2020/01/23/social-capital-in-silicon-valley/">Social Capital in Silicon Valley</a>. I like this blog because it helps me understand a place I only know from afar, because it’s a celebration of advantageous ambiguity, and because it demonstrates how to minimise upside regret. But you probably didn’t intend to read 4 blogs and a Wikipedia article when you clicked on this post, so here’s an excerpt that explains what social capital is and why it matters:</p>
<blockquote>
<p>Social capital ... is a form of wealth that can compound and throw off real dividends when it’s cultivated, or wither and die when it’s drawn down or neglected. Having access to social capital is a privilege. In the business world, social capital is earned over decades, and doled out carefully by those who have it: you can’t just give that stuff away.</p>
</blockquote>
<blockquote>
<p>Social capital is especially important if you’re trying to build something out of nothing, and need credibility and momentum in order to open doors and be taken seriously. Building startups outside of an established tech ecosystem is hard: there’s so much inertia and friction you have to fight that without existing momentum to draw from.</p>
</blockquote>
<p>So what’s so special about who has social capital in Silicon Valley? It&#39;s given out by people trying to minimise upside regret:</p>
<blockquote>
<p>Hang around for enough time in the Bay Area, and at some point you will meet someone – although you won’t know it at the time – who goes on to do something wildly successful. If you brush them off, it’ll come back to haunt you. </p>
</blockquote>
<p>I like to think that if more of us assume that others could do something brilliant, we’re probably going to increase the “capacity of individuals to have the power and resources to fulfill their potential”. </p>
<p>But, do our social environments really matter that much?</p>
<h2 id="cute_stories_about_supportive_social_circles">Cute stories about supportive social circles</h2>
<p>You’ll hear tales about well-known geniuses who were criticised and dismissed in their early careers, but that doesn’t mean we should ignore all criticism and plough on: just try and find critics that are encouraging rather than disparaging. In <em>Collaborative Circles</em>, Michael P. Farrell starts off by describing the friendship of J. R. R. Tolkien and C. S. Lewis:</p>
<blockquote>
<p>Nordic epics had enthralled Tolkien when he was a child. His fascination led him to create his own imaginary mythology, and from the time he was eighteen he worked sporadically at casting his stories of elves and wizards into an epic poem. Only once had he allowed anyone to see this work. In 1925 he showed it to an old mentor, who advised him to drop it. The rebuff reinforced his decision to keep the work secret. But after discovering that Lewis shared his interest in &quot;Northernness&quot; and epic poetry, a few days after the late night conversation, Tolkien gave Lewis one of the unfinished poems to read.</p>
</blockquote>
<p>Of course, Lewis spoke kindly of Tolkien’s work, saying:</p>
<blockquote>
<p>I can quite honestly say that it is ages since I have had an evening of such delight, and the personal experience of reading a friend&#39;s work had very little to do with it</p>
</blockquote>
<p>and then provided Tolkien with detailed-but-playful criticisms, which he gladly incorporated. This became the start of The Inklings, the pair’s literary discussion group, where the members read aloud their works in progress.</p>
<p>In 1960, Lewis wrote:</p>
<blockquote>
<p>Alone among unsympathetic companions, I hold certain views and standards timidly, half ashamed to avow them and half doubtful if they can after all be right. Put back among my friends and in half an hour—in ten minutes—these same views and standards become once more indisputable. The opinion of this little circle . . . outweighs that of a thousand outsiders..., it will do this even when my Friends are far away.</p>
</blockquote>
<p>And in 1977, Tolkien wrote &#40;about Lewis&#41;:		</p>
<blockquote>
<p>The unpayable debt I owe to him was not influence as it is usually understood, but sheer encouragement. He was for long my only audience. Only from him did I ever get the idea that my stuff could be more than a private hobby.</p>
</blockquote>
<p>I think this is &#40;1&#41; incredibly cute and &#40;2&#41; important&#33; We can kid ourselves about our sense of independence, but a lot of the most remarkable people needed encouragement from friends, and friends with whom they shared specific values and interests.</p>
<p>Farrell goes on to describe the French Impressionists, a prime example of a collaborative circle:</p>
<blockquote>
<p>Each year on the first of April, all artists were invited to submit three of their paintings to a jury of fourteen judges ... The jury members were the gatekeepers to the artistic world. Their approval legitimated the works of art and assured the middle class that an artist&#39;s work was a worthwhile investment. In their reviews of exhibits, the journalists, who also played a part in shaping the tastes of the middle class, took their cues from the academy and jury members. Only by exhibiting through the Salon and receiving favorable reviews could an artist become known, win commissions, and sell paintings.</p>
</blockquote>
<blockquote>
<p>Outdoor painting was not approved by the academy members, who saw the studio as the only place a painter could acquire the concentration and discipline to produce the clean lines and Platonic forms they considered real art. Monet, the most rebellious member of the circle, played a catalytic role at this point by persuading the other members to try the forbidden activity. </p>
</blockquote>
<blockquote>
<p>During the next few years, the group frequently painted in the Forest of Fontainebleau. While working side by side, the young painters shared their ideas about what art should be and began to develop their own vision. ... There were numerous false starts, and some of the most daring steps resulted in apparent failure. At any given moment, the members did not know whether they were making progress or following a dead-end tangent. But at each step, the courage to take a risk emerged out of the group dynamics, and the evaluation of the results took place in the group discussions.</p>
</blockquote>
<blockquote>
<p>As usual, Monet incorporated the innovations into his paintings the most boldly, but it is not possible to say whether he or Renoir initiated the new techniques. At several junctures in the group history, when Monet had &quot;led,&quot; he seemed to need an intimate audience for his experimentations. </p>
</blockquote>
<blockquote>
<p>It is not likely that either would have arrived at the new style alone, but together they had the courage to go beyond the limits, creating a new synthesis of the elements they had been working with. Perhaps Monet led, but would he have had the courage to pursue his own impulses or the judgment to know when they were worth retaining without Renoir as an alter ego? The paradigm that they were developing enabled them to reach consensus about which of their solutions to painting light and water were good solutions, and which should be abandoned. </p>
</blockquote>
<blockquote>
<p>After each rejection, or after a week of struggle and failure to achieve an artistic goal, the artists working alone must have begun to doubt their talents and the future of the group. But when meeting with the group in the ritualistic cafe setting, they would review recent events and interpret them in light of the group&#39;s emergent vision.</p>
</blockquote>
<blockquote>
<p>Having bypassed the Salon jury, the group&#39;s success depended on the evaluations of the public and the reviewers. However, the response to the first exhibit was nearly universal derision. Louis Leroy, the art critic for Charivari, wrote a satirical review in which he portrayed himself and an imaginary &quot;old master&quot; walking through the exhibit. Monet&#39;s Impression, Sunrise provoked Leroy&#39;s mocking attack on the whole exhibit. Over and over, when Leroy&#39;s &quot;old master&quot; expressed shock at an apparently unfinished work, the sketchy figures, and the bizarre colors, the reviewer would pretend to defend the work with the apology &quot;Yes, but the impression is there.&quot; ... By the third exhibition of 1876, the group had adopted the name themselves.<br/> The reaction of the public and the scarcity of buyers could have demoralized the group, but instead they rallied. The steadiness of Pissarro, &quot;the brain of the young movement, &quot; was important in keeping them together.</p>
</blockquote>
<blockquote>
<p>Rejection and meager sales continued at a group auction in 1875 and at a second group exhibition in 1876.</p>
</blockquote>
<p>I’m quite struck by their persistence: the core group formed in the early 1860s, was continually rejected from the Salon de Paris, and resorted to running their own exhibitions in 1874 &#40;which were, apparently, poorly received at first&#41;. Perhaps maintaining such persistence is ill-advised, but I don’t think their shared convictions were delusional — impressionism did turn out to be one of the most popular art movements of all time and, well, I think it’s all pretty good&#33;</p>
<div class="image"><img src="https://finnhambly.com/assets/monet-sunrise.jpg" alt="Impressionism, Sunrise" /></div>
<div class="caption">Claude Monet’s Impressionism, Sunrise &#40;1872&#41;. You’d think you’d know you were good if you made this, but when neither the public nor the art establishment approve, you better have supportive friends.</div>
<p>So talking to people seems good&#33; I bet you’re glad that you’re on this intellectual journey with me.</p>
<p>More seriously, I don’t think we should beat ourselves up over the fact we sometimes need some validation before we act on things. </p>
<p>But what if we find ourselves in unencouraging environments? What do we do about that?</p>
<h2 id="managing_how_were_affected_by_our_environments">Managing how we&#39;re affected by our environments</h2>
<p>Over the past couple of years, I’ve had a number of research ideas, which I’ve since found out are Certifiably Good and Cool, that I didn’t act upon straight away because my immediate contacts didn’t seem nearly as excited. In retrospect, I think I responded too strongly to people’s default, under-considered responses.</p>
<p>One response is to simply care less about validation and approval. Most of us sense that people will judge us for trying stuff out and making dumb things, but I expect it&#39;s our high expectations of ourselves that&#39;s really holding us back. </p>
<p>So care less. Give yourself <a href="https://thezvi.wordpress.com/2017/09/30/slack/">slack</a> so that it&#39;s easier to care less. Use your freedom to <a href="https://devjac.dev/posts/2019-12-19-exploit-your-interest.html">exploit your interest while it lasts</a>. Keep the stakes low and <a href="https://www.samstack.io/p/the-case-for-low-cost-ambition">do a side project</a>, making sure it’s <a href="http://www.paulgraham.com/own.html">a project of your own</a>. It’s still all upside&#33;</p>
<p>In practice, it can be quite hard to give up our fears and work directly towards our goals, especially when there are non-imagined constraints. Perhaps you need to justify buying expensive equipment, maybe you need to make a decision that precludes other options &#40;like a stable and obviously-impactful job&#41;, or you might know that any attempt you make will soon be derailed by crippling self-doubt.</p>
<div class="marginnote">I tend to think a lot about quite abstract things and I’ve mostly discussed agency with respect to actually doing something with those fuzzy ideas.</div>
<div class="marginnote"><br/>     If you just want to build clearly-defined skills, nothing beats <a href="https://nautil.us/not-all-practice-makes-perfect-4527/">deliberate practice</a>.</div>
<div class="marginnote"><br/>     But beware, because your metrics may not be your goals&#33; When I was in Year 12, I had a very clear goal, which was to get into Cambridge to study Natural Sciences. I’d previously read that you needed to average over 90&#37; in your AS Levels to have a chance of getting in — and so optimising my exam grades across my 5 subjects became my one-and-only target for the year.</div>
<div class="marginnote"><br/>     Weirdly, I have incredibly fond memories of the months before those exams; I knew every bit of the curriculum, I did a whole bunch of practice exam papers, and I understood every mistake I ever made. Having a metric to maximise &#40;i.e., number of correct answers&#41; and getting quick feedback gave me weeks worth of flow. And I smashed it. I got something like 97&#37; across my 5 AS levels. But, while that was fun and I learnt a lot, I still got rejected from Cambridge, so you should really make sure your optimisation strategy is properly aligned&#33; If you’re wanting to feel agentic, it’s easy to deceive yourself with the metrics that are most in your control.</div>
<p>So maybe we should give up on the idea of becoming überconfident and self-reliant, and simply hack our environments instead. It’s certainly rational to care about other people’s perceptions of us and our goals — especially since our ideas could be truly awful. But we have control over who we discuss ideas with and seek feedback from, and some people are considerably better placed to be helpful. </p>
<h2 id="some_personal_reflections">Some personal reflections</h2>
<p>Clearly there are specifics to who we seek feedback from — just finding people and talking at them with our ideas can backfire. I’ve had a bunch of weird ideas, but the things that randomly-selected individuals quickly understand and get excited about might not be correlated with what’s actually sensible for us. For instance, a few years ago, I had a phase of thinking up lots of ideas for scaling up seaweed farming to single-digit percentages of the Pacific, and got lots of positive excitement from friends when I spoke about it &#40;it’s pretty easy to understand how that could draw lots of carbon out the atmosphere&#41;. Since it was fun to talk about, I continued to think about how to make it work, even though I would’ve absolutely hated being a seaweed farmer. </p>
<p>Now, when I try to explain my ideas for enabling model-based, conditional forecasting tools, I mostly get blank faces. Perhaps I’ll read this back in a few years and realise that I should’ve pursued the seaweed farming all along 🤷🏻 but I think the blank faces are mainly a result of speaking with people who don&#39;t have enough context or ambitions in common with me.</p>
<p>I discovered that random university researchers can definitely be quite cheems-y because of these factors, but they’re relevant in more amenable settings too. Even at effective altruism conferences, where I tend to find people have lots of relevant intellectual context and shared values, I could still feel demoralised because someone didn’t have the time to fully understand what I was talking about. For sufficiently complex and nascent ideas, it can take a while before someone understands and says “yes, and...”</p>
<p>For me, the right people to test my thinking out with are friends I’ve made through <a href="https://www.effectivealtruism.org">EA</a> and, it turns out, longtermist grantmakers. There is nothing quite as agency-inducing as someone else backing you and your ideas financially &#40;but more on that in the future&#41;. </p>
<p>However, if the experiences of The Inklings and the French Impressionists are anything to go off of, fostering encouraging environments is more important than maximising our own sense of agency directly — we’ll probably get more out of it, too.</p>
<br/>
<div class="acknowledgements">Many thanks to Fin Moorhouse and Morgan Simpson for providing helpful feedback on a draft of this post :&#41;</div>
<script src="https://utteranc.es/client.js"
    repo="finnhambly/finnhambly.github.io"
    issue-term="pathname"
    theme="github-light"
    crossorigin="anonymous"
    async>
</script> ]]>
  </content:encoded>
    
  <pubDate>Tue, 28 Jun 2022 00:00:00 +0000</pubDate>  
  
  
  <atom:author>
    <atom:name>Finn Hambly</atom:name>
  </atom:author>
        
</item>

<item>
  <title>
    <![CDATA[  The servers are on the moon &#40;2072&#41;  ]]>
  </title>
  <link> https://finnhambly.com/blog/2072/index.html </link>
  <guid> https://finnhambly.com/blog/2072/index.html </guid>
  <description>
    <![CDATA[  You were right about mind uploading being a big deal, though that was obvious in 2022, right?  ]]>
  </description>  
  
  <content:encoded>
    <![CDATA[  
<h1 id="the_servers_are_on_the_moon_2072">The servers are on the moon &#40;2072&#41;</h1>
<p>Hi, past Finn. I thought it was a bit weird of you to write a letter to yourself in 50 years’ time, given that all your stated beliefs on emerging technologies involved either the end of civilisation or the digitisation of human life. Still, I’m glad you did&#33; </p>
<p>You were right about mind uploading being a big deal, though that was obvious in 2022, right? A lot has changed but, as far as I can tell, I’m still made of atoms rather than bits — inhabiting “meatspace” as you put it… &#40;I haven’t heard that term in a long time&#41;</p>
<p>As for the AI stuff, it’s good at art and science — and it basically powers everything — but it doesn’t <em>decide</em> anything, really. &#40;I don’t know how to succinctly explain agency during circumstances that follow Drexler&#39;s law of specialised software ascendancy; I have various mnemonic media on <em>The Political Economy of Automatic Differentiators</em>, but attaching it would kill the old-timey feel of this letter.&#41; All that really matters is that, a few decades ago, a hodgepodge of development schemes were made to avoid &#40;vaguely-defined&#41; combinations of ‘learned optimisation’ and ‘agency’. It essentially means that impressive AI systems never had enough autonomy and goal-directedness to destroy everything on their own.</p>
<h2 id="211">\(2^{11}\)</h2>
<blockquote>
<p>So in Cana of Galilee Jesus did his first miracle. There he showed his glory, and his followers believed in him. &#40;John, 2:11&#41;</p>
</blockquote>
<p>Okay, it wasn&#39;t really as straightforward as having just &quot;a hodgepodge of development schemes&quot;. We got AI systems that could do practically all our research <em>in silico</em>, and research labs took the line of &#39;tool AI first&#39;. We seemed to have a better idea of how to actually execute Bostrom&#39;s &#39;differential technological development&#39;. I felt that way, at least, given that I spent 13 years working on those strategies.</p>
<p>I still think the researchers were doing the pro-social thing, but tools and agents aren&#39;t always so distinct &#40;especially in the hands of fallible humans&#41;. By 2048, it was clear that AI systems were basically capable of turning water into wine: increasing computational capabilities bred better algorithmic improvements, of course, and those algorithmic improvements quickly brought about better comp…— you know the deal.</p>
<p>A generally intelligent artificial agent: there were a scary few years when it totally could’ve been made &#40;even by a small lab&#41;. Everyone in the world knew the risks, but that wasn&#39;t exactly sufficient for mitigating them. Instead we had some incredibly oppressive policing of all computational research and no monolithic superintelligence was created.</p>
<p>I thought there might be a combination of defensive technologies that would inhibit single agents from becoming dominant, but I couldn&#39;t tell you what that would be even now &#40;21 years later&#41;. We&#39;d had a shitload of AI-generated technological breakthroughs, including lots of scary biological stuff, as well as &#40;more significantly&#41; absurdly productive factories that started displacing almost all other economic activity. Unlike me, every smart person was focused on either &#40;1&#41; exploiting the power dynamics resulting from this economic environment, or &#40;2&#41; designing political institutions for uploaded minds.</p>
<p>After the recent — and somewhat-palatable — use of oppressive surveillance, property confiscation, and censorship, the political consensus was to prevent the non-democractic usage of all advanced AI tools. Forgive me if I sound ambivalent about all of this, since I <em>am</em> grateful that civilisation is still here, etcetera etcetera. The trouble with quashing all personal usage of advanced technology, in a world that is determined by said technology, is that it extinguishes any sense of individual agency. But I&#39;m rather old fashioned now and the younger generation aren&#39;t as hung up on &#39;changing the world&#39; as us narcissistic millenials. I moan about value lock-in and lost potential, but my kids either ignore me or tell me &quot;you can create your utopia when you&#39;re uploaded&quot;.</p>
<h2 id="the_emulation_population">The emulation population</h2>
<p>As for mind uploading, it’s kind of just everyone’s afterlife. We all know we’ll end up creating lots of pure ems &#40;i.e. people whose minds never ran on wetware&#41;, but Robin Hanson’s legacy was to scare a ton of people shitless about an intergalactic capitalist expansion of enslaved consciousnesses. Cue some spicy population-ethics debates among your friends on whether a Malthusian collapse is ‘necessarily’ a ‘moral catastrophe’, while the rest of the world sensibly decides to <em>seize the means of emulation</em> and socialise the crap out of that industry.</p>
<p>Anyway, the servers are on the moon. Like the literal moon. I find it kind of weird looking up and thinking about the 1.4 billion consciousnesses there, but it’s not like you can see any of the heatsink infrastructure yet. The ems are doing a fair bit of philosophising before they expand to other planetary systems, but they mostly play games as far as I can tell.</p>
<p><img src="https://finnhambly.com/images/moon.jpeg" alt="" /></p>
<p>Em-life seems fine, something to look forward to, but it’s kind of abstract. I thought it’d be weird being trapped in a computer, but all the ems I know say it’s not like that, and you evolve new sensory experiences. I ask them what a normal day is like, and all of them seem bemused by the concept — I guess they don’t have ‘day’s? Or perhaps the notion of ‘normal’ is now alien to them, I don’t know. I’ll understand it more clearly when I’m there but we don’t have any approved way of reinhabiting a human body and so I’m savouring my time in this one while it lasts.</p>
<br/>
<p>Down here we mainly focus on how we’re going to make Earth nicer in the short-term. A lot of our physical infrastructure has been replaced so that its upkeep and maintenance is automated, so now we, uh, design stuff? We’ll generate things like new sports equipment, stand-up comedy routines, and rapid transit carriages filled with art and nice armchairs. We discuss economics and politics and study the cosmos &#40;as reported back by our probes&#41;. No sign of other life, yet&#33;</p>
<p>The key result is that our cities are absolutely lovely. Everywhere is like the Netherlands, but now with <strong>zero</strong> cars and far, far fewer sharp objects. The fact that we have the prospect of eternal life has made us much more risk averse. We mourn every unexpected loss. Pre-emptive brain scans are taken, but — essentially for quasi-spiritual reasons — everyone plans on being uploaded as they die. We don’t talk about it much.</p>
<p>All the best, <br/> Finn</p>
<script src="https://utteranc.es/client.js"
    repo="finnhambly/finnhambly.github.io"
    issue-term="pathname"
    theme="github-light"
    crossorigin="anonymous"
    async>
</script> ]]>
  </content:encoded>
    
  <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>  
  
  
  <atom:author>
    <atom:name>Finn Hambly</atom:name>
  </atom:author>
        
</item>
</channel></rss>